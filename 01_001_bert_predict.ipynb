{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "01_001_bert_predict.ipynb",
   "provenance": [],
   "machine_shape": "hm",
   "collapsed_sections": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyPWO61yw16B2fpiS2oYsQBy"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "01Bf3mzmeyjx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654754526981,
     "user_tz": -540,
     "elapsed": 3929,
     "user": {
      "displayName": "S_C is My Life",
      "userId": "00146971668477874710"
     }
    },
    "outputId": "2850d37d-4dcf-4b0d-8bb7-d993150a057a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
      "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-l1xiwlrb\n",
      "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-l1xiwlrb\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.24.5)\n",
      "Requirement already satisfied: gluonnlp>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.10.0)\n",
      "Requirement already satisfied: mxnet>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.9.1)\n",
      "Requirement already satisfied: onnxruntime==1.8.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.8.0)\n",
      "Requirement already satisfied: sentencepiece>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.1.96)\n",
      "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.11.0+cu113)\n",
      "Requirement already satisfied: transformers>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (4.19.2)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (2.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (1.21.6)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (3.17.3)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (0.29.30)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (21.3)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.3) (0.8.4)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.3) (2.23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->kobert==0.2.3) (4.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (0.7.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (2019.12.20)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (0.12.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (3.7.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.64.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.11.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp>=0.6.0->kobert==0.2.3) (3.0.9)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->kobert==0.2.3) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->kobert==0.2.3) (1.0.0)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.5 in /usr/local/lib/python3.7/dist-packages (from boto3->kobert==0.2.3) (1.27.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.5->boto3->kobert==0.2.3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.5->boto3->kobert==0.2.3) (1.15.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.8.1->kobert==0.2.3) (3.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "iAUfYzm6e2Vk",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654754528793,
     "user_tz": -540,
     "elapsed": 1818,
     "user": {
      "displayName": "S_C is My Life",
      "userId": "00146971668477874710"
     }
    },
    "outputId": "19a6ce64-a5e2-4b2c-9279-dc0b2f76a145"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split "
   ],
   "metadata": {
    "id": "ki7oBVBIfBDk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654754533658,
     "user_tz": -540,
     "elapsed": 4867,
     "user": {
      "displayName": "S_C is My Life",
      "userId": "00146971668477874710"
     }
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ],
   "metadata": {
    "id": "pweuSENOgDJf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654754539065,
     "user_tz": -540,
     "elapsed": 5410,
     "user": {
      "displayName": "S_C is My Life",
      "userId": "00146971668477874710"
     }
    },
    "outputId": "868ea722-c9f6-4f34-9d05-f1e3291b4eff"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "using cached model. /content/.cache/kobert_v1.zip\n",
      "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ],
   "metadata": {
    "id": "Sg-Z14edgACK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654754539067,
     "user_tz": -540,
     "elapsed": 12,
     "user": {
      "displayName": "S_C is My Life",
      "userId": "00146971668477874710"
     }
    },
    "outputId": "78bffaa3-9c73-4cba-c1ce-bc3492a11d0b"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "## Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 30\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5\n"
   ],
   "metadata": {
    "id": "Y2wtLch-gKOC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654754539067,
     "user_tz": -540,
     "elapsed": 10,
     "user": {
      "displayName": "S_C is My Life",
      "userId": "00146971668477874710"
     }
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ],
   "metadata": {
    "id": "8hcLrI3sgTMy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654754539068,
     "user_tz": -540,
     "elapsed": 11,
     "user": {
      "displayName": "S_C is My Life",
      "userId": "00146971668477874710"
     }
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# new_test = nlp.data.TSVDataset(\"/content/drive/MyDrive/Watching_You_PJ/project_ChatBot/02_preprocessing/BERT/train/01_001_bert_train.tsv\" , field_indices=[0,2], num_discard_samples=1)\n",
    "# test_set = BERTDataset(new_test , 0, 1, tok, max_len, True, False)\n",
    "# test_input = torch.utils.data.DataLoader(test_set, batch_size=1, num_workers=4)"
   ],
   "metadata": {
    "id": "JzVv-clcfnED",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654754539068,
     "user_tz": -540,
     "elapsed": 10,
     "user": {
      "displayName": "S_C is My Life",
      "userId": "00146971668477874710"
     }
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/Watching_You_PJ/project_ChatBot/02_preprocessing/01_001_bert.csv')\n",
    "df"
   ],
   "metadata": {
    "id": "CIa9sun6g12-",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654754539068,
     "user_tz": -540,
     "elapsed": 10,
     "user": {
      "displayName": "S_C is My Life",
      "userId": "00146971668477874710"
     }
    },
    "outputId": "f2e145eb-007c-4d73-ab40-a88c48a36e9f"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        SENTENCE   MAIN  num\n",
       "0                   아이스아메리카노 하나요   일반주문    0\n",
       "1                   네 텀블러에 넣어주세요  텀블러사용    1\n",
       "2                   그란데 사이즈로 주세요   일반주문    0\n",
       "3                  저 카푸치노로 주문할게요   일반주문    0\n",
       "4     그럼 2000원 추가해서 브레드도 같이 시킬게요   결제요청    2\n",
       "...                          ...    ...  ...\n",
       "3043               하우스 블렌딩은 뭐예요?   메뉴문의    8\n",
       "3044       약간 산미 나는 걸로 한 잔 주실래요?   일반주문    0\n",
       "3045                마시고 가면 얼마예요?   일반주문    0\n",
       "3046                영수증 하나 주실래요?  영수증요청   45\n",
       "3047            차는 어디에 세울 수 있어요?   주차문의   61\n",
       "\n",
       "[3048 rows x 3 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-f16c2328-7402-4ab2-866a-e6b62af4e970\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>MAIN</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아이스아메리카노 하나요</td>\n",
       "      <td>일반주문</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네 텀블러에 넣어주세요</td>\n",
       "      <td>텀블러사용</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그란데 사이즈로 주세요</td>\n",
       "      <td>일반주문</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>저 카푸치노로 주문할게요</td>\n",
       "      <td>일반주문</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>그럼 2000원 추가해서 브레드도 같이 시킬게요</td>\n",
       "      <td>결제요청</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>하우스 블렌딩은 뭐예요?</td>\n",
       "      <td>메뉴문의</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3044</th>\n",
       "      <td>약간 산미 나는 걸로 한 잔 주실래요?</td>\n",
       "      <td>일반주문</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>마시고 가면 얼마예요?</td>\n",
       "      <td>일반주문</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>영수증 하나 주실래요?</td>\n",
       "      <td>영수증요청</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>차는 어디에 세울 수 있어요?</td>\n",
       "      <td>주차문의</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3048 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f16c2328-7402-4ab2-866a-e6b62af4e970')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f16c2328-7402-4ab2-866a-e6b62af4e970 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f16c2328-7402-4ab2-866a-e6b62af4e970');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "category_list = list(df['MAIN'].unique())\n",
    "category_list\n",
    "cat_len = len(category_list)\n",
    "cat_len"
   ],
   "metadata": {
    "id": "1qHnR-LDg6lj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654754539069,
     "user_tz": -540,
     "elapsed": 10,
     "user": {
      "displayName": "S_C is My Life",
      "userId": "00146971668477874710"
     }
    },
    "outputId": "17e7108c-6175-449f-c219-c08697f66b8f"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=cat_len,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        else:\n",
    "            out = pooler\n",
    "        return self.classifier(out)"
   ],
   "metadata": {
    "id": "B0oVnS6qhL0R",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654754539069,
     "user_tz": -540,
     "elapsed": 9,
     "user": {
      "displayName": "S_C is My Life",
      "userId": "00146971668477874710"
     }
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)\n",
    "model.load_state_dict(torch.load('/content/drive/MyDrive/Watching_You_PJ/project_ChatBot/03_DL_Model/01_001_bert_10.pth'))"
   ],
   "metadata": {
    "id": "Y_0rG6eNg8Aj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1654754543337,
     "user_tz": -540,
     "elapsed": 4276,
     "user": {
      "displayName": "S_C is My Life",
      "userId": "00146971668477874710"
     }
    },
    "outputId": "1cf6c4ff-9ab7-408d-b445-6d49e0aef17d"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 문장 예측을 위한 함수 정의 : 문자 길이에 대한\n",
    "def predict(predict_sentence):\n",
    "\n",
    "    if len(predict_sentence) <5 :\n",
    "        print(\"너무 짧아요\")\n",
    "        return False\n",
    "    else:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      data = [predict_sentence, '0']\n",
    "      dataset_another = [data]\n",
    "\n",
    "      another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "\n",
    "      test_dataloader = DataLoader(another_test, batch_size=batch_size, num_workers=4)\n",
    "      # print(test_dataloader)\n",
    "      # for i in test_dataloader:\n",
    "      #     print(i)\n",
    "     \n",
    "\n",
    "      for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "          token_ids = token_ids.long().to(device)\n",
    "          segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "          valid_length= valid_length\n",
    "          label = label.long().to(device)\n",
    "\n",
    "          out = model(token_ids, valid_length, segment_ids)\n",
    "          prediction = out.cpu().detach().numpy().argmax()\n",
    "\n",
    "          test_eval=[]\n",
    "          test_eval_2=[]\n",
    "          for i in out:\n",
    "              logits=i\n",
    "              logits = logits.detach().cpu().numpy()\n",
    "          for k , c in enumerate(category_list):\n",
    "          # for k,(c,p) in enumerate(zip(category_list,prediction)):\n",
    "              \n",
    "              if np.argmax(logits) == k:\n",
    "                  value = logits[k]\n",
    "                  value  = round(value*10)\n",
    "                  if value <50 :\n",
    "                      print(\"죄송합니다 다시 말씀해주세요\")\n",
    "                      print(value)\n",
    "                      # print()\n",
    "                      test_eval.append(c)\n",
    "                      value = logits[k]\n",
    "                      test_eval_2.append(value)\n",
    "                      print(\">> 입력하신 내용에서 \" + test_eval[0] + \" 느껴집니다.\")\n",
    "\n",
    "                      return False\n",
    "                  else :\n",
    "                      test_eval.append(c)\n",
    "                      value = logits[k]\n",
    "                      test_eval_2.append(value)\n",
    "\n",
    "              # elif np.argmax(logits) == 1:\n",
    "              #     test_eval.append(\"텀블라사용\")\n",
    "\n",
    "          print(\">> 입력하신 내용에서 \" + test_eval[0] + \" 느껴집니다.\")\n",
    "          # print(value)\n",
    "          print(test_eval_2[0])\n",
    "\n",
    "end = 1\n",
    "while end == 1 :\n",
    "    sentence = input(\"하고싶은 말을 입력해주세요(5자 이상) : \")\n",
    "    if sentence == 0 :\n",
    "        \n",
    "        break\n",
    "    predict(sentence)\n",
    "\n",
    "\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "id": "5791Jbydg-aD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "end = 1\n",
    "while end == 1 :\n",
    "    sentence = input(\"하고싶은 말을 입력해주세요(5자 이상) : \")\n",
    "    if sentence == 0 :\n",
    "        \n",
    "        break\n",
    "    predict(sentence)\n",
    "\n",
    "\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "id": "onVXrknah4Hs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "NZy8npOZh5yc"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}